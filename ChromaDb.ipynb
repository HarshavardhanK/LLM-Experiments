{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "embed_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client and a new collection\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# load from disk\n",
    "#db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "#chroma_collection = db2.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    service_context=service_context,\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is a watermark z hypothesis score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the provided context information, a watermark Z hypothesis score refers to a metric used to evaluate the performance of a language model in detecting or resisting attacks on its ability to generate coherent and natural-sounding text. The term \"watermark\" likely refers to the idea of embedding a hidden message or signature within the language model\\'s output, which can be detected later to assess its authenticity or tampering.\\n\\nThe \"Z\" in the hypothesis score may represent the experimenter\\'s z-score, which is a statistical measure used to compare the observed frequency of an event to the expected frequency under a null hypothesis. In this context, the Z score could indicate how many standard deviations the language model\\'s performance deviates from the expected performance when tested against various attacks or manipulations.\\n\\nWithout prior knowledge of the specific context or experiment, it is difficult to provide a more detailed explanation of the watermark Z hypothesis score.', source_nodes=[NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='8186207f-6438-4698-abbe-85206b14405d', embedding=None, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bab86b7d-eb4a-4fa1-bd25-a1e1c76b93ce', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='8a050775ad1c7d0817ef607302f73796f4464ef3d2c3847a15f217f66feeb05c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2932bfff-5218-4d77-8dc5-70c9926ca097', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='7578214a5f5d48897dab760c9639d9dee2e61791592f0266319ad3e7c219197a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ab55a27-3868-4ca8-a493-1f03ec359d76', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='31dbd5c47b03577001ee65ca7ab3b584574de97b488f3d7d84b861ad3d7fef3c')}, hash='6eddead46c3900c2fbd48f7f8df311616402a1657ab79d006fd6f59e3cd62849', text='Association\\nfor Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.163. URL https://aclanthology.\\norg/2020.emnlp-main.163 .\\nTay, Y ., Bahri, D., Zheng, C., Brunk, C., Metzler, D., and\\nTomkins, A. Reverse Engineering Configurations of Neu-\\nral Text Generation Models. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pp. 275–279, Online, July 2020. Association\\nfor Computational Linguistics. doi: 10.18653/v1/2020.acl-main.25. URL https://aclanthology.org/\\n2020.acl-main.25 .\\nTay, Y ., Dehghani, M., Tran, V . Q., Garcia, X., Bahri, D.,\\nSchuster, T., Zheng, H. S., Houlsby, N., and Metzler, D.\\nUnifying language learning paradigms. arXiv preprint\\narXiv:2205.05131 , 2022.\\nTian, E. Gptzero update v1, January 2023. URL https:\\n//gptzero.substack.com/p/gptzero-\\nupdate-v1 .\\nTopkara, M., Riccardi, G., Hakkani-T ¨ur, D., and\\nAtallah, M. J. Natural language watermarking: Chal-\\nlenges in building a practical system. In Security,\\nSteganography, and Watermarking of Multimedia\\nContents VIII , volume 6072, pp. 106–117. SPIE,\\nFebruary 2006a. doi: 10.1117/12.643560. URL\\nhttps://www.spiedigitallibrary.org/\\nconference-proceedings-of-spie/6072/\\n60720A/Natural-language-watermarking-\\nchallenges-in-building-a-practical-\\nsystem/10.1117/12.643560.full .\\nTopkara, U., Topkara, M., and Atallah, M. J. The hiding\\nvirtues of ambiguity: Quantifiably resilient watermark-\\ning of natural language text through synonym substitu-\\ntions. In Proceedings of the 8th Workshop on Multi-\\nmedia and Security , MM&amp;Sec ’06, pp. 164–174,\\nNew York, NY , USA, September 2006b. Association\\nfor Computing Machinery. ISBN 978-1-59593-493-2.\\ndoi: 10.1145/1161366.1161397. URL https://doi.\\norg/10.1145/1161366.1161397 .\\nUeoka, H., Murawaki, Y ., and Kurohashi, S. Frustratingly\\nEasy Edit-based Linguistic Steganography with a Masked\\nLanguage Model. In Proceedings of the 2021 Conference\\nof the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technolo-\\ngies, pp. 5486–5492, Online, June 2021. Association for\\nComputational Linguistics. doi: 10.18653/v1/2021.naacl-\\nmain.433. URL https://aclanthology.org/\\n2021.naacl-main.433 .\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\\nL., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention\\nIs All You Need. arXiv:1706.03762 [cs] , December 2017.\\nURL http://arxiv.org/abs/1706.03762 .\\nVenugopal, A., Uszkoreit, J., Talbot, D., Och, F., and\\nGanitkevitch, J. Watermarking the Outputs of Struc-\\ntured Prediction with an application in Statistical Ma-\\nchine Translation. In Proceedings of the 2011 Confer-\\nence on Empirical Methods in Natural Language Pro-\\ncessing , pp. 1363–1372, Edinburgh, Scotland, UK., July\\n2011. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/D11-1126 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, '8186207f-6438-4698-abbe-85206b14405d': {'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Who is the main author who introduced soft watermark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The main author who introduced soft watermark is Wilson, A. Soft watermarking is discussed in their paper \"A Watermark for Large Language Models\" published in 2014.', source_nodes=[NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, '4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The algorithm introduced by Kirchenbauer is a hard watermarking algorithm, which means it embeds a watermark into the media in a way that makes it difficult to remove or tamper with. The algorithm uses a Z-score hypothesis to generate the watermark, which is a statistical technique used to detect and identify potential tampering of the media.\\n\\nIn simple terms, the algorithm takes a media sample (such as an image or audio file) and calculates a Z-score for each pixel or sample. The Z-score represents how many standard deviations away from the mean the sample is. The algorithm then uses these Z-scores to generate a watermark that is embedded into the media in a way that makes it difficult to remove or tamper with.\\n\\nThe idea behind this algorithm is that any attempt to remove or tamper with the watermark will alter the Z-scores of the media, making it possible to detect the tampering. This provides a high level of security and authenticity to the media, ensuring that it can be trusted and verified.', source_nodes=[NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, '67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What does the algoroithm introduced by Kirchenbauer do?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
