{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "embed_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client and a new collection\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db2.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index2 = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index2.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is a watermark z hypothesis score?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the provided context information, a watermark Z hypothesis score refers to a metric used to evaluate the performance of a language model in detecting or resisting attacks on its ability to generate coherent and natural-sounding text. The term \"watermark\" likely refers to the idea of embedding a hidden message or signature within the language model\\'s output, which can be detected later to assess its authenticity or tampering.\\n\\nThe \"Z\" in the hypothesis score may represent the experimenter\\'s z-score, which is a statistical measure used to compare the observed frequency of an event to the expected frequency under a null hypothesis. In this context, the Z score could indicate how many standard deviations the language model\\'s performance deviates from the expected performance when tested against various attacks or manipulations.\\n\\nWithout prior knowledge of the specific context or experiment, it is difficult to provide a more detailed explanation of the watermark Z hypothesis score.', source_nodes=[NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='8186207f-6438-4698-abbe-85206b14405d', embedding=None, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bab86b7d-eb4a-4fa1-bd25-a1e1c76b93ce', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='8a050775ad1c7d0817ef607302f73796f4464ef3d2c3847a15f217f66feeb05c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='2932bfff-5218-4d77-8dc5-70c9926ca097', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='7578214a5f5d48897dab760c9639d9dee2e61791592f0266319ad3e7c219197a'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4ab55a27-3868-4ca8-a493-1f03ec359d76', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='31dbd5c47b03577001ee65ca7ab3b584574de97b488f3d7d84b861ad3d7fef3c')}, hash='6eddead46c3900c2fbd48f7f8df311616402a1657ab79d006fd6f59e3cd62849', text='Association\\nfor Computational Linguistics. doi: 10.18653/v1/2020.\\nemnlp-main.163. URL https://aclanthology.\\norg/2020.emnlp-main.163 .\\nTay, Y ., Bahri, D., Zheng, C., Brunk, C., Metzler, D., and\\nTomkins, A. Reverse Engineering Configurations of Neu-\\nral Text Generation Models. In Proceedings of the 58th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pp. 275–279, Online, July 2020. Association\\nfor Computational Linguistics. doi: 10.18653/v1/2020.acl-main.25. URL https://aclanthology.org/\\n2020.acl-main.25 .\\nTay, Y ., Dehghani, M., Tran, V . Q., Garcia, X., Bahri, D.,\\nSchuster, T., Zheng, H. S., Houlsby, N., and Metzler, D.\\nUnifying language learning paradigms. arXiv preprint\\narXiv:2205.05131 , 2022.\\nTian, E. Gptzero update v1, January 2023. URL https:\\n//gptzero.substack.com/p/gptzero-\\nupdate-v1 .\\nTopkara, M., Riccardi, G., Hakkani-T ¨ur, D., and\\nAtallah, M. J. Natural language watermarking: Chal-\\nlenges in building a practical system. In Security,\\nSteganography, and Watermarking of Multimedia\\nContents VIII , volume 6072, pp. 106–117. SPIE,\\nFebruary 2006a. doi: 10.1117/12.643560. URL\\nhttps://www.spiedigitallibrary.org/\\nconference-proceedings-of-spie/6072/\\n60720A/Natural-language-watermarking-\\nchallenges-in-building-a-practical-\\nsystem/10.1117/12.643560.full .\\nTopkara, U., Topkara, M., and Atallah, M. J. The hiding\\nvirtues of ambiguity: Quantifiably resilient watermark-\\ning of natural language text through synonym substitu-\\ntions. In Proceedings of the 8th Workshop on Multi-\\nmedia and Security , MM&amp;Sec ’06, pp. 164–174,\\nNew York, NY , USA, September 2006b. Association\\nfor Computing Machinery. ISBN 978-1-59593-493-2.\\ndoi: 10.1145/1161366.1161397. URL https://doi.\\norg/10.1145/1161366.1161397 .\\nUeoka, H., Murawaki, Y ., and Kurohashi, S. Frustratingly\\nEasy Edit-based Linguistic Steganography with a Masked\\nLanguage Model. In Proceedings of the 2021 Conference\\nof the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technolo-\\ngies, pp. 5486–5492, Online, June 2021. Association for\\nComputational Linguistics. doi: 10.18653/v1/2021.naacl-\\nmain.433. URL https://aclanthology.org/\\n2021.naacl-main.433 .\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\\nL., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention\\nIs All You Need. arXiv:1706.03762 [cs] , December 2017.\\nURL http://arxiv.org/abs/1706.03762 .\\nVenugopal, A., Uszkoreit, J., Talbot, D., Och, F., and\\nGanitkevitch, J. Watermarking the Outputs of Struc-\\ntured Prediction with an application in Statistical Ma-\\nchine Translation. In Proceedings of the 2011 Confer-\\nence on Empirical Methods in Natural Language Pro-\\ncessing , pp. 1363–1372, Edinburgh, Scotland, UK., July\\n2011. Association for Computational Linguistics. URL\\nhttps://aclanthology.org/D11-1126 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, '8186207f-6438-4698-abbe-85206b14405d': {'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Who is the main author who introduced soft watermark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The main author who introduced soft watermark is Wilson, A. Soft watermarking is discussed in their paper \"A Watermark for Large Language Models\" published in 2014.', source_nodes=[NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, '4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The algorithm introduced by Kirchenbauer is a hard watermarking algorithm, which means it embeds a hidden signature or mark into the image or audio that cannot be removed or tampered with. The algorithm uses a Z-score hypothesis to ensure the watermark is robust and resistant to attacks. The Z-score hypothesis is a statistical measure that calculates the number of standard deviations an observed value is away from the mean. In the context of hard watermarking, the algorithm embeds the watermark in a way that makes it highly likely to be detected even if the image or audio is modified or distorted.', source_nodes=[NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, '67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What does the algoroithm introduced by Kirchenbauer do?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the context provided, we can infer that Harsha loves to trek in the Himalayas and go on adventures. Specifically, he had a recent adventure to Kedarkantha and plans to go to Manaslu circuit in 2027. Additionally, the passage mentions that Harsha was seeing the Watermarking algorithm in his trip to Manali, which suggests that he may have been working on or interested in this topic related to language models during his travels. However, there is no direct mention of what Harsha loves to do in his free time.', source_nodes=[NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, '4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What does Harsha love to do?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the provided context information, the article \"A Watermark for Large Language Models\" by Wilson et al. (2014) mentions an improvement in watermarking that is distortion-free. Specifically, the authors propose a method for linguistic steganography on Twitter that uses hierarchical language modeling with manual interaction. They claim that their approach is able to embed a watermark into a text message without introducing any distortions or degradations in the message\\'s meaning or content.\\n\\nThe article Zellers et al. (2019) also discusses the use of neural network-based methods for defending against neural fake news, and mentions that their approach is able to achieve a high degree of accuracy without introducing any distortions into the input data.\\n\\nOverall, these articles suggest that there have been improvements in watermarking and other natural language processing techniques that allow for the embedding of information into texts or other forms of media without introducing distortions or degradations.', source_nodes=[NodeWithScore(node=TextNode(id_='4ab55a27-3868-4ca8-a493-1f03ec359d76', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e981df77-62e5-4eca-a238-04eaebc7f59c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8186207f-6438-4698-abbe-85206b14405d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='eb256452-99a0-4895-853e-4dd09bdce860', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='1dd8c1d6-24fc-405f-8fcd-39c320cc34e8', embedding=None, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e41f35ca-8805-497e-8f49-19f12fe2df70', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4adc1f1a5af40dd8d051a5c9c288b50f8f70c339ed1745f2040e61a451baccbc'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c21c1efc-77cf-4fc7-b5a6-9e20ad398630', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '16', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='6486b4e389240224f0279fc098b0b4ff76f13a4a5b85e6745d277f1acd6f85b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='42c5d7d5-ef78-459b-bdee-9df70df8b160', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='d83e8c37cbce95dbf8b98acc68dd4bff666ab84b41bd14fcc0a12ea692a9f500')}, hash='7cd9e710c23598b7fd6971715f5441f2358e32bde9bb5b7d7640b13e150992ef', text='A Watermark for Large Language Models.\\nWilson, A., Blunsom, P., and Ker, A. D. Linguis-\\ntic steganography on Twitter: Hierarchical lan-\\nguage modeling with manual interaction. In Me-\\ndia Watermarking, Security, and Forensics 2014 ,\\nvolume 9028, pp. 9–25. SPIE, February 2014.\\ndoi: 10.1117/12.2039213. URL https://www.\\nspiedigitallibrary.org/conference-\\nproceedings-of-spie/9028/902803/\\nLinguistic-steganography-on-Twitter--\\nhierarchical-language-modeling-with-\\nmanual/10.1117/12.2039213.full .\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtow-\\nicz, M., Davison, J., Shleifer, S., von Platen, P., Ma,\\nC., Jernite, Y ., Plu, J., Xu, C., Scao, T. L., Gugger,\\nS., Drame, M., Lhoest, Q., and Rush, A. M. Hugging-\\nFace’s Transformers: State-of-the-art Natural Language\\nProcessing. arXiv:1910.03771 [cs] , July 2020. URL\\nhttp://arxiv.org/abs/1910.03771 .\\nWolff, M. and Wolff, S. Attacking Neural Text Detectors.\\narxiv:2002.11768[cs] , January 2022. doi: 10.48550/\\narXiv.2002.11768. URL http://arxiv.org/abs/\\n2002.11768 .\\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi,\\nA., Roesner, F., and Choi, Y . Defending Against Neural\\nFake News. In Advances in Neural Information Pro-\\ncessing Systems , volume 32. Curran Associates,\\nInc., 2019. URL https://proceedings.\\nneurips.cc/paper/2019/hash/\\n3e9f0fc9b2f89e043bc6233994dfcf76-\\nAbstract.html .\\nZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M.,\\nChen, S., Dewan, C., Diab, M., Li, X., Lin, X. V ., Mi-\\nhaylov, T., Ott, M., Shleifer, S., Shuster, K., Simig, D.,\\nKoura, P. S., Sridhar, A., Wang, T., and Zettlemoyer,\\nL. Opt: Open pre-trained transformer language models,\\n2022.\\nZhu, J., Kaplan, R., Johnson, J., and Fei-Fei, L.\\nHiDDeN: Hiding Data with Deep Networks. In\\nProceedings of the European Conference on Computer\\nVision (ECCV) , pp. 657–672, 2018. URL https:\\n//openaccess.thecvf.com/content_ECCV_\\n2018/html/Jiren_Zhu_HiDDeN_Hiding_\\nData_ECCV_2018_paper.html .\\nZiegler, Z., Deng, Y ., and Rush, A. Neural Linguistic\\nSteganography. In Proceedings of the 2019 Conference\\non Empirical Methods in Natural Language Processing\\nand the 9th International Joint Conference on Natural\\nLanguage Processing (EMNLP-IJCNLP) , pp. 1210–1215,\\nHong Kong, China, November 2019. Association forComputational Linguistics. doi: 10.18653/v1/D19-1115.\\nURL https://aclanthology.org/D19-1115 .', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'4ab55a27-3868-4ca8-a493-1f03ec359d76': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, '1dd8c1d6-24fc-405f-8fcd-39c320cc34e8': {'page_label': '17', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"What was the improvement in watermarking that was distortion free?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Based on the context provided in the text, it seems that Harsha is a software engineer who loves to trek in the Himalayas. He has recently been on a trip to Manali where he encountered the Watermarking algorithm. A shopkeeper asked him to explain Kirchenbauer\\'s Z score hypothesis for hard watermarking, which suggests a method for embedding watermarks into images in a way that makes them robust to distortions.\\n\\nThe paper \"Robust Distortion-free Watermarking\" proposes a new approach to watermarking that is designed to be robust against various types of attacks, including cropping, scaling, and rotation. The proposed method uses a combination of data embedding and spread spectrum techniques to create a hidden signature that can be detected even if the image is distorted.\\n\\nIn summary, the paper \"Robust Distortion-free Watermarking\" proposes a new method for watermarking that is designed to be robust against various types of attacks, and can be used to protect images from unauthorized use or manipulation.', source_nodes=[NodeWithScore(node=TextNode(id_='dfc22922-9e83-40b9-90eb-5b477213c032', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c20c08e2-3ae3-49cc-a696-8681eb8f4543', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1edf6e43-9926-4f25-b45b-1b5990e39f74', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '57', 'file_name': 'Robust Distortion-free Watermarks for Language Models.pdf', 'file_path': 'data/Robust Distortion-free Watermarks for Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 3370336, 'creation_date': '2023-11-20', 'last_modified_date': '2023-11-12', 'last_accessed_date': '2023-11-20'}, hash='07d82dc71d0e74cb51b1b92c1f646cc62b4d0e33032aafe1d50d10335ec48e1f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a6c05b4f-71d6-4a1c-abed-fd0c2727d3eb', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='67d12342-c9c1-4c34-8991-a798946b36e7', embedding=None, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f119c43-f062-48bf-81cc-44a15bc44210', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='8097479cd31abca46d33e77b525c01d3e50433af0fa7a24dd1ef46fcd9ea6f5d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='06cf9e84-f1d2-419f-aecd-f51c87b113af', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='4bffb4a26b2a9cd422ff2a931ecc175e6cdf9a021457bada241e1d209e9d7d8d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='397abd13-9950-41e9-8a0a-2cc14c9fcc91', node_type=<ObjectType.IMAGE: '2'>, metadata={'file_path': 'data/mountain_pic.jpg', 'file_name': 'mountain_pic.jpg', 'file_type': 'image/jpeg', 'file_size': 78118, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a')}, hash='4ceddbfc1352acc37e5e8173623767ca9795b961fd837e9a836239db7820f1be', text=\"Harsha is a brilliant software engineer and he loves to trek in the Himalayas. \\nHis trek to Hampta Pass was canceled due to heavy floods in Manali\\nHis recent adventure to Kedarkantha was transformative and he plans to go to Manaslu circuit in 2027.\\n\\nHarsha was seeing the Watermarking algorithm in his trip to Manali. \\nA shopkeeper asked him to explain what was Kirchenbauer's Z score hypothesis for hard watermarking.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'dfc22922-9e83-40b9-90eb-5b477213c032': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}, '67d12342-c9c1-4c34-8991-a798946b36e7': {'file_path': 'data/harsha.txt', 'file_name': 'harsha.txt', 'file_type': 'text/plain', 'file_size': 418, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-19', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"Summarize what the paper 'Robust Distortion-free watermarking' proposes\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Sure! Here are two possible questions that could be generated based on the concepts of watermarking discussed in the provided text:\\n\\nQuestion 1: What is the optimal value of γ for a pareto-optimal small green list in a watermarking scheme, and why?\\n\\nThis question is prompted by the statement in the text that \"a small green list, γ=.1is pareto-optimal.\" The question asks for the reason behind this optimization and the optimal value of γ that leads to the best performance.\\n\\nQuestion 2: How does beam search affect the tradeoff between watermark strength and accuracy, and what are the implications of this interaction for the design of a watermarking scheme?\\n\\nThis question is inspired by the observation in the text that \"beam search has a synergistic interaction with the soft watermarking rule.\" The question seeks to understand the nature of this interaction and how it impacts the performance of the watermarking scheme.', source_nodes=[NodeWithScore(node=TextNode(id_='3c466002-0c32-4555-b87d-28a427a67907', embedding=None, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e2326e0e-5ab4-49f2-81a2-446c7039cb05', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='a3ba8e03616854950fb47d536797fb8a8e43381ffb8ceff4a2bc657da8c1ed26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b3f5c298-e455-49bc-95dc-92d521d4aa20', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='2204f8abc70f6607eb6be0b77bdbcb47e6b89f4bab3dccd7ff7e251ebf1298fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='91fbddde-6333-4f25-a3b6-77bc616be55b', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='392a0b0bab9f4c328d3a515c08e10d28ecb0afd7b7d2c1576f0095b0cc402d97')}, hash='b6b356134e86286eb28e225469695bdb37849174a5facfc8abb93fd987fb78f9', text='Interestingly, we see that\\na small green list, γ=.1is pareto-optimal.\\nIn addition to these quantitative results, we show exam-\\nples of real prompts and watermarked outputs in Table 1 to\\nprovide a qualitative sense for the behavior of the test statis-\\ntic and quality measurement on different kinds of prompts.\\nAdditional examples are compiled in Appendix A.1.\\nIroning in the Watermark with Beam Search. Figure 2(right) shows the tradeoff between watermark strength and\\naccuracy when beam search is used. Beam search has a\\nsynergistic interaction with the soft watermarking rule. Par-\\nticularly when 8 beams are used, the points in Figure 2 form\\nan almost vertical line, showing very little perplexity cost to\\nachieve strong watermarking.\\nWatermark Strength vs Number of Tokens. Theory pre-\\ndicts that the type I and type II error rates of the watermark\\nshould decay to zero as the sequence length Tincreases.\\nFigure 3 shows the strength of the watermark, measured\\nusing the average z-score over samples, as Tsweeps from 2\\nto 200. Curves are shown for various values of δandγ. The\\nleft two charts use multinomial sampling, while the right\\nchart uses 8-way beam search and γ=.25. Once again, we\\nsee the power of the beam search in achieving high green\\nlist ratios; even for the moderate bias of δ= 2, an average\\nz-score greater than 5 is achieved for as few as 35 tokens.\\nPerformance and Sensitivity for Multinomial Sampling.\\nTo show the sensitivity of the resulting hypothesis test based', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0), NodeWithScore(node=TextNode(id_='c5366841-efec-450c-a130-934e6f8ca47a', embedding=None, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9891364b-a976-4a4c-92eb-25a790fb819b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='a3ba8e03616854950fb47d536797fb8a8e43381ffb8ceff4a2bc657da8c1ed26'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ddf54565-cf27-448c-a447-cb09ccabbcf8', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='2204f8abc70f6607eb6be0b77bdbcb47e6b89f4bab3dccd7ff7e251ebf1298fa'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6d4bc5ee-7418-41d9-b16a-4b20883a8c98', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '9', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, hash='392a0b0bab9f4c328d3a515c08e10d28ecb0afd7b7d2c1576f0095b0cc402d97')}, hash='b6b356134e86286eb28e225469695bdb37849174a5facfc8abb93fd987fb78f9', text='Interestingly, we see that\\na small green list, γ=.1is pareto-optimal.\\nIn addition to these quantitative results, we show exam-\\nples of real prompts and watermarked outputs in Table 1 to\\nprovide a qualitative sense for the behavior of the test statis-\\ntic and quality measurement on different kinds of prompts.\\nAdditional examples are compiled in Appendix A.1.\\nIroning in the Watermark with Beam Search. Figure 2(right) shows the tradeoff between watermark strength and\\naccuracy when beam search is used. Beam search has a\\nsynergistic interaction with the soft watermarking rule. Par-\\nticularly when 8 beams are used, the points in Figure 2 form\\nan almost vertical line, showing very little perplexity cost to\\nachieve strong watermarking.\\nWatermark Strength vs Number of Tokens. Theory pre-\\ndicts that the type I and type II error rates of the watermark\\nshould decay to zero as the sequence length Tincreases.\\nFigure 3 shows the strength of the watermark, measured\\nusing the average z-score over samples, as Tsweeps from 2\\nto 200. Curves are shown for various values of δandγ. The\\nleft two charts use multinomial sampling, while the right\\nchart uses 8-way beam search and γ=.25. Once again, we\\nsee the power of the beam search in achieving high green\\nlist ratios; even for the moderate bias of δ= 2, an average\\nz-score greater than 5 is achieved for as few as 35 tokens.\\nPerformance and Sensitivity for Multinomial Sampling.\\nTo show the sensitivity of the resulting hypothesis test based', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.0)], metadata={'3c466002-0c32-4555-b87d-28a427a67907': {'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}, 'c5366841-efec-450c-a130-934e6f8ca47a': {'page_label': '8', 'file_name': 'A Watermark for Large Language Models.pdf', 'file_path': 'data/A Watermark for Large Language Models.pdf', 'file_type': 'application/pdf', 'file_size': 1472891, 'creation_date': '2023-11-19', 'last_modified_date': '2023-11-04', 'last_accessed_date': '2023-11-19'}})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\"Create 2 questions from the concepts of watermarking\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
